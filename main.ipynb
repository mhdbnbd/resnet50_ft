{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bcvezHVonZ2"
      },
      "source": [
        "import sys\n",
        "# path to the root\n",
        "sys.path.append('/content/drive/MyDrive/resnet50_ft')\n",
        "import torch\n",
        "from data.preprocess import load_ds\n",
        "from model.model_construct import Model_Construct\n",
        "from train import predict_batchwise, train_model\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj9z9tyKotcS"
      },
      "source": [
        "## Typical experiment on SVHN/MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWdzLO9ioxg3"
      },
      "source": [
        "print(\"----SVHN2MNIST----\")\n",
        "acc_mnist_ls = []\n",
        "# set the number of experiments to run\n",
        "for i in range(2):\n",
        "  #load model\n",
        "  model_10 = Model_Construct(num_classes=10).to(device)\n",
        "  #load dataloaders\n",
        "  mnist_trainloader, mnist_testloader, svhn_trainloader, svhn_testloader = load_ds(datasets=\"mnist/svhn\", batch_size=64, num_workers=4, grayscale = True, normalize = False)\n",
        "  # define training data\n",
        "  print(\"--Source: svhn--\")\n",
        "  source_dataloader = {'train': svhn_trainloader, 'val': svhn_testloader}\n",
        "  # train\n",
        "  svhn_model, svhn_hist = train_model(model_10, source_dataloader, num_epochs=2, lr=0.00025, weight_decay=0, instNorm=True)\n",
        "  # test\n",
        "  print(\"--Target: mnist--\")\n",
        "  print(\"-Prediction on mnist:\")\n",
        "  acc_mnist, _ = predict_batchwise(svhn_model, mnist_testloader)\n",
        "  acc_mnist_ls.append(acc_mnist)\n",
        "# average accuracy\n",
        "print(\"--Average accuracy--\")\n",
        "acc_mnist_ls = [tensor.tolist() for tensor in acc_mnist_ls]\n",
        "mnist_std = np.std(acc_mnist_ls)\n",
        "mnist_mean = np.mean(acc_mnist_ls)\n",
        "print(\"Average accuracy on MNIST: {:.3f}({:.3f})\".format(mnist_mean, mnist_std))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CZxEEOXo-eo"
      },
      "source": [
        "## Typical experiment on Office-31"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oPA50C7pE_I"
      },
      "source": [
        "print(\"----Office31----\")\n",
        "acc_webcam_ls = []\n",
        "acc_dslr_ls = []\n",
        "# set the number of experiments to run\n",
        "for i in range(8):\n",
        "  # load model\n",
        "  model_31 = Model_Construct(num_classes=31).to(device)\n",
        "  # load dataloaders\n",
        "  amazon_loader, amazon_halfloader, amazon_half2loader, webcam_loader, webcam_halfloader, webcam_half2loader, dslr_loader, dslr_halfloader, dslr_half2loader = load_ds(datasets=\"office31\", batch_size=64, num_workers=4, grayscale=False, normalize=False, split_path=os.path.join(\"/content/drive/MyDrive/resnet50_ft\", \"data/splits_structure\"), ds_path=os.path.join(\"/content/drive/MyDrive/resnet50_ft\", \"data/Office31\"))\n",
        "  print(\"--Source: Amazon--\")\n",
        "  # define training data\n",
        "  source_dataloader = {'train': amazon_halfloader, 'val': amazon_half2loader}\n",
        "  # train\n",
        "  amazon_model, amazon_hist = train_model(model_31, source_dataloader, num_epochs=200, lr=0.001,  weight_decay=0.0001, instNorm=False)\n",
        "  # test\n",
        "  print(\"--Target: Webcam, DSLR--\")\n",
        "  print(\"Prediction on webcam:\")\n",
        "  acc_webcam, _ = predict_batchwise(amazon_model, webcam_loader)\n",
        "  acc_webcam_ls.append(acc_webcam)\n",
        "  print(\"Prediction on DSLR:\")\n",
        "  acc_dslr, _ = predict_batchwise(amazon_model, dslr_loader)\n",
        "  acc_dslr_ls.append(acc_dslr)\n",
        "\n",
        "# average accuracy\n",
        "print(\"--Average accuracy--\")\n",
        "acc_webcam_ls = [tensor.tolist() for tensor in acc_webcam_ls]\n",
        "webcam_std = np.std(acc_webcam_ls)\n",
        "webcam_mean = np.mean(acc_webcam_ls)\n",
        "print(\"Average accuracy on Webcam: {:.3f}({:.3f})\".format(webcam_mean, webcam_std))\n",
        "\n",
        "acc_dslr_ls = [tensor.tolist() for tensor in acc_dslr_ls]\n",
        "dslr_std = np.std(acc_dslr_ls)\n",
        "dslr_mean = np.mean(acc_dslr_ls)\n",
        "print(\"Average accuracy on DSLR: {:.3f}({:.3f})\".format(dslr_mean, dslr_std))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}